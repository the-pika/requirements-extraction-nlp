{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import spacy\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the spaCy model for linguistic feature extraction\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Set the device for running the model (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "def extract_linguistic_features(text):\n",
        "    doc = nlp(text)\n",
        "    features = {}\n",
        "\n",
        "    # Part-of-speech (POS) tags\n",
        "    pos_tags = [token.pos_ for token in doc]\n",
        "    features['pos_tags'] = pos_tags\n",
        "\n",
        "    # Named Entity Recognition (NER) entities\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    features['entities'] = entities\n",
        "\n",
        "    # Dependency parsing\n",
        "    dependency_tree = []\n",
        "    for token in doc:\n",
        "        dependency_tree.append((token.text, token.dep_, token.head.text))\n",
        "    features['dependency_tree'] = dependency_tree\n",
        "\n",
        "    return features\n",
        "\n",
        "def calculate_similarity(sentence1, sentence2):\n",
        "    # Tokenize the sentences\n",
        "    inputs = tokenizer([sentence1, sentence2], padding=True, truncation=True, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "    # Forward pass through the BERT model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Get the BERT embeddings\n",
        "    sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    # Calculate the cosine similarity between the sentence embeddings\n",
        "    similarity_score = torch.nn.functional.cosine_similarity(sentence_embeddings[0].unsqueeze(0), sentence_embeddings[1].unsqueeze(0))\n",
        "    return similarity_score.item()\n",
        "\n",
        "# Problem statement\n",
        "problem_statement = \"As the client, I am the manager of a busy public library. We are seeking a software company to develop a Library Management System (LMS) to replace our existing manual processes.\"\n",
        "\n",
        "# Entities and relationships\n",
        "entities = [\"Library Management System\", \"book catalog\", \"user management\", \"circulation and borrowing\", \"public library\", \"library operations\", \"efficiency\", \"experience\", \"issued books\", \"staff\", \"patrons\", \"analytics\"]\n",
        "relationships = [\"automate\", \"user authentication\", \"access control\", \"checkout\", \"return\", \"renewal\", \"improve\", \"enhance\", \"provide\", \"for\"]\n",
        "\n",
        "# Extract candidate domain concepts using semantic similarity\n",
        "candidate_concepts = []\n",
        "for entity in entities:\n",
        "    max_score = -1.0\n",
        "    max_relationship = \"\"\n",
        "\n",
        "    for relationship in relationships:\n",
        "        combined_text = f\"{entity} {relationship}\"\n",
        "        similarity_score = calculate_similarity(problem_statement, combined_text)\n",
        "\n",
        "        if similarity_score > max_score:\n",
        "            max_score = similarity_score\n",
        "            max_relationship = relationship\n",
        "\n",
        "    candidate_concepts.append({\n",
        "        'entity': entity,\n",
        "        'relationship': max_relationship,\n",
        "        'similarity_score': max_score\n",
        "    })\n",
        "\n",
        "# Extract linguistic features for the candidate concepts\n",
        "for concept in candidate_concepts:\n",
        "    linguistic_features = extract_linguistic_features(concept['entity'])\n",
        "    concept['linguistic_features'] = linguistic_features\n",
        "\n",
        "# Print the extracted candidate domain concepts\n",
        "for concept in candidate_concepts:\n",
        "    print(\"Entity:\", concept['entity'])\n",
        "    print(\"Relationship:\", concept['relationship'])\n",
        "    print(\"Similarity Score:\", concept['similarity_score'])\n",
        "    print(\"Linguistic Features:\", concept['linguistic_features'])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAJi2K40tp9A",
        "outputId": "5ec70b94-fd8d-4a25-df04-9b64ea220c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Library Management System\n",
            "Relationship: access control\n",
            "Similarity Score: 0.7616750001907349\n",
            "Linguistic Features: {'pos_tags': ['PROPN', 'PROPN', 'PROPN'], 'entities': [('Library Management System', 'ORG')], 'dependency_tree': [('Library', 'compound', 'Management'), ('Management', 'compound', 'System'), ('System', 'ROOT', 'System')]}\n",
            "\n",
            "Entity: book catalog\n",
            "Relationship: return\n",
            "Similarity Score: 0.7209666967391968\n",
            "Linguistic Features: {'pos_tags': ['NOUN', 'NOUN'], 'entities': [], 'dependency_tree': [('book', 'compound', 'catalog'), ('catalog', 'ROOT', 'catalog')]}\n",
            "\n",
            "Entity: user management\n",
            "Relationship: user authentication\n",
            "Similarity Score: 0.7295514345169067\n",
            "Linguistic Features: {'pos_tags': ['NOUN', 'NOUN'], 'entities': [], 'dependency_tree': [('user', 'compound', 'management'), ('management', 'ROOT', 'management')]}\n",
            "\n",
            "Entity: circulation and borrowing\n",
            "Relationship: access control\n",
            "Similarity Score: 0.7200219631195068\n",
            "Linguistic Features: {'pos_tags': ['NOUN', 'CCONJ', 'NOUN'], 'entities': [], 'dependency_tree': [('circulation', 'ROOT', 'circulation'), ('and', 'cc', 'circulation'), ('borrowing', 'conj', 'circulation')]}\n",
            "\n",
            "Entity: public library\n",
            "Relationship: automate\n",
            "Similarity Score: 0.7236817479133606\n",
            "Linguistic Features: {'pos_tags': ['ADJ', 'NOUN'], 'entities': [], 'dependency_tree': [('public', 'amod', 'library'), ('library', 'ROOT', 'library')]}\n",
            "\n",
            "Entity: library operations\n",
            "Relationship: access control\n",
            "Similarity Score: 0.739570677280426\n",
            "Linguistic Features: {'pos_tags': ['NOUN', 'NOUN'], 'entities': [], 'dependency_tree': [('library', 'compound', 'operations'), ('operations', 'ROOT', 'operations')]}\n",
            "\n",
            "Entity: efficiency\n",
            "Relationship: user authentication\n",
            "Similarity Score: 0.7009627819061279\n",
            "Linguistic Features: {'pos_tags': ['NOUN'], 'entities': [], 'dependency_tree': [('efficiency', 'ROOT', 'efficiency')]}\n",
            "\n",
            "Entity: experience\n",
            "Relationship: access control\n",
            "Similarity Score: 0.7123715877532959\n",
            "Linguistic Features: {'pos_tags': ['VERB'], 'entities': [], 'dependency_tree': [('experience', 'ROOT', 'experience')]}\n",
            "\n",
            "Entity: issued books\n",
            "Relationship: access control\n",
            "Similarity Score: 0.7023341655731201\n",
            "Linguistic Features: {'pos_tags': ['VERB', 'NOUN'], 'entities': [], 'dependency_tree': [('issued', 'ROOT', 'issued'), ('books', 'dobj', 'issued')]}\n",
            "\n",
            "Entity: staff\n",
            "Relationship: access control\n",
            "Similarity Score: 0.6996871829032898\n",
            "Linguistic Features: {'pos_tags': ['NOUN'], 'entities': [], 'dependency_tree': [('staff', 'ROOT', 'staff')]}\n",
            "\n",
            "Entity: patrons\n",
            "Relationship: user authentication\n",
            "Similarity Score: 0.7087698578834534\n",
            "Linguistic Features: {'pos_tags': ['NOUN'], 'entities': [], 'dependency_tree': [('patrons', 'ROOT', 'patrons')]}\n",
            "\n",
            "Entity: analytics\n",
            "Relationship: access control\n",
            "Similarity Score: 0.70697021484375\n",
            "Linguistic Features: {'pos_tags': ['NOUN'], 'entities': [], 'dependency_tree': [('analytics', 'ROOT', 'analytics')]}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}